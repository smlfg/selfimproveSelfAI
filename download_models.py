#!/usr/bin/env python3
"""
Modell-Download-Skript f√ºr GGUF-Modelle von Hugging Face
"""
import os
import subprocess
import sys
from pathlib import Path

# Empfohlene GGUF-Modelle (klein bis gro√ü)
RECOMMENDED_MODELS = [
    {
        "name": "Phi-3.5-Mini-Instruct (4B) - Q4_K_M",
        "repo": "microsoft/Phi-3.5-mini-instruct-gguf",
        "file": "Phi-3.5-mini-instruct-Q4_K_M.gguf",
        "size": "~2.4GB",
        "description": "Kleines, schnelles Modell - ideal f√ºr Tests"
    },
    {
        "name": "Llama-3.2-3B-Instruct - Q4_K_M", 
        "repo": "huggingface/Llama-3.2-3B-Instruct-Q4_K_M-GGUF",
        "file": "llama-3.2-3b-instruct-q4_k_m.gguf",
        "size": "~1.9GB",
        "description": "Meta Llama 3.2 - sehr gut f√ºr Chat"
    },
    {
        "name": "Qwen2.5-7B-Instruct - Q4_K_M",
        "repo": "Qwen/Qwen2.5-7B-Instruct-GGUF", 
        "file": "qwen2.5-7b-instruct-q4_k_m.gguf",
        "size": "~4.4GB",
        "description": "Alibaba Qwen - sehr gute Qualit√§t"
    }
]

def check_huggingface_cli():
    """Pr√ºfe ob huggingface-cli verf√ºgbar ist"""
    try:
        result = subprocess.run(['huggingface-cli', '--help'], 
                              capture_output=True, text=True)
        return result.returncode == 0
    except FileNotFoundError:
        return False

def setup_hf_token():
    """Setup Hugging Face Token"""
    print("üîë Hugging Face Token Setup")
    print("-" * 40)
    
    token = input("Bitte geben Sie Ihren Hugging Face Token ein: ").strip()
    
    if not token:
        print("‚ùå Kein Token eingegeben")
        return False
    
    try:
        # Login with token
        result = subprocess.run(['huggingface-cli', 'login', '--token', token],
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Hugging Face Login erfolgreich!")
            return True
        else:
            print(f"‚ùå Login fehlgeschlagen: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå Fehler beim Login: {e}")
        return False

def download_model(model_info):
    """Lade ein spezifisches Modell herunter"""
    print(f"\nüì• Lade {model_info['name']} herunter...")
    print(f"   Repository: {model_info['repo']}")
    print(f"   Datei: {model_info['file']}")
    print(f"   Gr√∂√üe: {model_info['size']}")
    
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    try:
        # Download mit huggingface-cli
        cmd = [
            'huggingface-cli', 'download',
            model_info['repo'],
            model_info['file'],
            '--local-dir', str(models_dir),
            '--local-dir-use-symlinks', 'False'
        ]
        
        print(f"üîÑ F√ºhre aus: {' '.join(cmd)}")
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            downloaded_file = models_dir / model_info['file']
            if downloaded_file.exists():
                size_mb = downloaded_file.stat().st_size / (1024*1024)
                print(f"‚úÖ Download erfolgreich! ({size_mb:.1f} MB)")
                return str(downloaded_file)
            else:
                print("‚ùå Datei nach Download nicht gefunden")
                return None
        else:
            print(f"‚ùå Download fehlgeschlagen: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"‚ùå Fehler beim Download: {e}")
        return None

def update_config(model_path):
    """Aktualisiere config.yaml mit neuem Modellpfad"""
    try:
        import yaml
        
        # Lade aktuelle Config
        with open("config.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        # Aktualisiere CPU-Fallback Pfad
        if "cpu_fallback" not in config:
            config["cpu_fallback"] = {}
        
        config["cpu_fallback"]["model_path"] = model_path
        
        # Speichere Config
        with open("config.yaml", "w") as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"‚úÖ config.yaml aktualisiert mit: {model_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå Fehler beim Aktualisieren der Config: {e}")
        return False

def main():
    print("üöÄ GGUF Modell Download f√ºr NPU/CPU Chat")
    print("=" * 50)
    
    # Pr√ºfe huggingface-cli
    if not check_huggingface_cli():
        print("‚ùå huggingface-cli nicht gefunden!")
        print("üí° Installieren Sie es mit: pip install huggingface_hub[cli]")
        sys.exit(1)
    
    print("‚úÖ huggingface-cli verf√ºgbar")
    
    # Setup Token
    if not setup_hf_token():
        print("‚ùå Hugging Face Login fehlgeschlagen")
        sys.exit(1)
    
    # Zeige verf√ºgbare Modelle
    print("\nüìã Verf√ºgbare Modelle:")
    for i, model in enumerate(RECOMMENDED_MODELS, 1):
        print(f"{i}. {model['name']}")
        print(f"   {model['description']}")
        print(f"   Gr√∂√üe: {model['size']}")
        print()
    
    # Benutzer-Auswahl
    try:
        choice = input("Welches Modell m√∂chten Sie herunterladen? (1-3): ").strip()
        choice_idx = int(choice) - 1
        
        if 0 <= choice_idx < len(RECOMMENDED_MODELS):
            selected_model = RECOMMENDED_MODELS[choice_idx]
            
            # Download
            model_path = download_model(selected_model)
            
            if model_path:
                # Config aktualisieren
                if update_config(model_path):
                    print("\nüéâ Setup komplett!")
                    print("üí° Testen Sie jetzt: python npu_chat.py")
                else:
                    print(f"\n‚ö†Ô∏è Modell heruntergeladen, aber Config-Update fehlgeschlagen")
                    print(f"   Manuell eintragen in config.yaml: {model_path}")
            else:
                print("\n‚ùå Download fehlgeschlagen")
        else:
            print("‚ùå Ung√ºltige Auswahl")
    
    except (ValueError, KeyboardInterrupt):
        print("\nüõë Abgebrochen")

if __name__ == "__main__":
    main()