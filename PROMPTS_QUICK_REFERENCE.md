# üéØ SelfAI Prompts - Quick Reference

Schneller √úberblick √ºber alle Prompts in SelfAI.

---

## 1Ô∏è‚É£ PLANNER Prompt

**File**: `selfai/core/planner_minimax_interface.py:89-183`

**Purpose**: User-Goal ‚Üí DPPM JSON Plan

**Key Points**:
- ‚úÖ Nur reines JSON (kein Markdown, keine Backticks)
- ‚úÖ **NICHT im Thinking-Bereich!** (wichtig f√ºr MiniMax)
- ‚úÖ Parallelisierung optimieren (gleiche `parallel_group` = gleichzeitig)

**Template**:
```
Du agierst als DPPM-Planer f√ºr SelfAI...
Erzeuge ausschlie√ülich JSON:
{
  "subtasks": [...],
  "merge": {...}
}

KRITISCH:
- Liefere JSON in Antwort-Ausgabe (NICHT in <think> Tags!)
```

---

## 2Ô∏è‚É£ SUBTASK Prompt

**File**: `selfai/core/execution_dispatcher.py` (uses Agent system prompts)

**Purpose**: Einzeltask ausf√ºhren

**Template**:
```
System: {agent.system_prompt}
User: {subtask.objective}
History: {relevant_memory}
```

**Key Points**:
- Nutzt Agent-spezifische System Prompts (z.B. "Code Helfer")
- Objective sollte pr√§gnant sein (max 160 Zeichen)

---

## 3Ô∏è‚É£ MERGER Prompt ‚≠ê (Kritischster Prompt!)

**File**: `selfai/selfai.py:479-507`

**Purpose**: Subtask-Ergebnisse ‚Üí Koh√§rente Gesamt-Antwort

**Template**:
```
Du bist ein Experte f√ºr Ergebnis-Synthese im DPPM-System.

URSPR√úNGLICHES ZIEL (User-Frage):
{original_goal}

AUSGEF√úHRTE SUBTASKS:
{combined_outputs}

KRITISCHE ANFORDERUNGEN:
1. FOKUS: Beantworte NUR die User-Frage (keine Meta-Diskussion!)
2. DIREKTHEIT: Beginne sofort (kein "Ich werde...", kein "Lass mich...")
3. SYNTHESE: Kombiniere intelligent (nicht copy-paste)
4. KEINE <think> Tags!
5. KEINE Meta-Kommentare √ºber Merge-Prozess!

AUSGABE-FORMAT:
- Markdown-Formatierung (## √úberschriften, - Listen)
- Direkt mit Antwort beginnen
- Bei Code: Integrierten, lauff√§higen Code

ERSTELLE JETZT DIE FINALE ANTWORT:
```

**Post-Processing** (Zeile 588-594):
```python
# Automatisches Filtern von <think> Tags
merge_response = re.sub(r'<think>.*?</think>', '', merge_response, flags=re.DOTALL)
```

**Common Fixes**:
- ‚ùå `<think>` Tags ‚Üí ‚úÖ Explizites Verbot + Regex-Filter
- ‚ùå "Ich werde jetzt..." ‚Üí ‚úÖ "DIREKTHEIT: Beginne sofort"
- ‚ùå Meta-Kommentare ‚Üí ‚úÖ "FOKUS: Beantworte NUR User-Frage"

---

## 4Ô∏è‚É£ GEMINI JUDGE Prompt

**File**: `selfai/core/gemini_judge.py:176-228`

**Purpose**: Qualit√§ts-Bewertung (nach Merge)

**Template**:
```
Du bist ein unabh√§ngiger Evaluator f√ºr AI-Agenten.

**ORIGINAL GOAL:** {goal}
**EXECUTION OUTPUT:** {subtasks + merge}
**EXECUTION TIME:** {time}
**FILES CHANGED:** {files}

Bewerte auf Skala 0-10:
1. Task Completion (0=gar nicht, 10=perfekt)
2. Code Quality (0=schlecht, 10=exzellent)
3. Efficiency (0=verschwenderisch, 10=optimal)
4. Goal Adherence (0=verfehlt, 10=genau getroffen)

Antworte NUR mit JSON (kein anderer Text!):
{
  "task_completion": 8.5,
  "code_quality": 7.0,
  "efficiency": 9.0,
  "goal_adherence": 8.0,
  "summary": "Kurze Zusammenfassung",
  "strengths": [...],
  "weaknesses": [...],
  "recommendations": [...]
}
```

**Key Points**:
- ‚úÖ One-Shot Mode (`gemini` ohne Flags) ‚Üí Keine Session-Pollution
- ‚úÖ `stderr=DEVNULL` ‚Üí Keine Startup-Logs
- ‚úÖ Evaluiert **nach** Merge (komplette Pipeline)

---

## üìä Prompt-Kette (Flow)

```
User Input: "Erkl√§re Python Decorators"
    ‚Üì
PLANNER: Zerlege in Subtasks
    ‚Üí S1: "Decorator Konzept erkl√§ren"
    ‚Üí S2: "Code-Beispiel erstellen"
    ‚Üí S3: "Use Cases zeigen"
    ‚Üì
SUBTASKS: F√ºhre einzeln aus
    ‚Üí S1 Result: "Decorators sind..."
    ‚Üí S2 Result: "@decorator\ndef..."
    ‚Üí S3 Result: "Logging, Caching..."
    ‚Üì
MERGER: Kombiniere zu koh√§renter Antwort
    ‚Üí "## Python Decorators\nDecorators sind... [S1+S2+S3]"
    ‚Üì
GEMINI JUDGE: Bewerte Qualit√§t
    ‚Üí Task Completion: 9.0/10
    ‚Üí Overall: üü¢ 85/100
```

---

## üîß Quick Debugging

### Problem: Merger zeigt `<think>` Tags

**Symptom**:
```
<think>Alright, let's get this done...</think>
Ich werde jetzt die Subtasks kombinieren...
```

**Fix**:
1. Check Merger Prompt (Zeile 479-507): Enth√§lt "KEINE `<think>` Tags!"?
2. Check Regex Filter (Zeile 588-594): Aktiv?
3. Test mit: `grep "<think>" memory/*/merge_*.txt`

### Problem: Planner gibt JSON in `<think>` Tags

**Symptom**: Plan wird als "JSON-Parsing fehlgeschlagen" rejected

**Fix**: Check Planner Prompt hat "Liefere JSON **nicht im Thinking-Bereich**"

### Problem: Merger beantwortet nicht die User-Frage

**Symptom**: Meta-Diskussion √ºber Merge-Prozess statt Antwort

**Fix**: Check "FOKUS: Beantworte NUR die User-Frage" ist prominent

---

## üìù Prompt-Editing Workflow

1. **Lokalisiere Prompt**:
   ```bash
   grep -rn "Du agierst als\|Du bist ein" selfai/core selfai/selfai.py
   ```

2. **Edit in Place**:
   ```bash
   # Merger Prompt
   vim selfai/selfai.py +479

   # Planner Prompt
   vim selfai/core/planner_minimax_interface.py +89
   ```

3. **Test sofort**:
   ```bash
   python selfai/selfai.py
   /plan Test neue Merger-Prompt-Version
   ```

4. **Measure Impact**:
   ```bash
   # Count <think> tags in recent merges
   grep -c "<think>" memory/*/merge_*.txt | awk -F: '{sum+=$2} END{print sum}'
   ```

---

## üéØ Best Practices

### ‚úÖ DO:
- Explizite Constraints ("KEINE `<think>` Tags!")
- Negative Instructions f√ºr kritische Points
- Post-Processing Filter als Failsafe
- Constraint-First Prompting (Constraints VOR Task)

### ‚ùå DON'T:
- Vage Anweisungen ("Gib eine gute Antwort")
- Nur positive Instructions (auch sagen was NICHT tun!)
- Constraints am Ende (LLMs vergessen sie)
- Ohne Post-Processing Filter

---

## üìö Siehe auch

- `PROMPT_ENGINEERING_GUIDE.md` - Vollst√§ndiger wissenschaftlicher Guide
- `GEMINI_JUDGE_GUIDE.md` - Judge-System Details
- `CLAUDE.md` - Projekt-Architektur

---

**Last Updated**: 2025-12-18
