#!/bin/bash
# Einfaches Modell-Setup Skript

echo "üöÄ Modell-Setup f√ºr NPU/CPU Chat"
echo "=================================="

# Virtual Environment aktivieren
source venv/bin/activate

echo "‚úÖ Virtual Environment aktiviert"

# √úberpr√ºfe HF CLI
echo "üîç √úberpr√ºfe Hugging Face CLI..."
if huggingface-cli --help > /dev/null 2>&1; then
    echo "‚úÖ Hugging Face CLI ist verf√ºgbar"
else
    echo "‚ùå Hugging Face CLI nicht gefunden"
    exit 1
fi

# Models Verzeichnis erstellen
mkdir -p models
echo "‚úÖ Models-Verzeichnis bereit"

echo ""
echo "üìã N√§chste Schritte:"
echo "1. F√ºhren Sie aus: huggingface-cli login --token IHR_TOKEN"
echo "2. Dann: huggingface-cli download microsoft/Phi-3.5-mini-instruct-gguf Phi-3.5-mini-instruct-Q4_K_M.gguf --local-dir models --local-dir-use-symlinks False"
echo "3. Warten Sie auf den Download (~2.4GB)"
echo "4. Testen Sie: python npu_chat.py"
echo ""
echo "üí° Kleinere Alternative (nur 1GB):"
echo "   huggingface-cli download huggingface/Llama-3.2-1B-Instruct-Q4_K_M-GGUF llama-3.2-1b-instruct-q4_k_m.gguf --local-dir models --local-dir-use-symlinks False"