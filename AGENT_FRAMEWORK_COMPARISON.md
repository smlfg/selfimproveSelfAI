# Agent Framework Comparison fÃ¼r SelfAI

**Datum**: 2025-01-21
**Ziel**: SelfAI zu einem echten Tool-Using Agent machen
**Kontext**: MiniMax Interface braucht Tool-Calling, smolagents bereits vorhanden

---

## ğŸ¯ Requirements fÃ¼r SelfAI

1. **Tool-Calling Support**: Muss Tools automatisch aufrufen kÃ¶nnen
2. **MiniMax KompatibilitÃ¤t**: Funktioniert mit custom LLM (nicht nur OpenAI)
3. **Existing Tools**: Nutzt vorhandene 15 Tools aus tool_registry.py
4. **UI Integration**: Kann Tool-Calls an UI melden
5. **Performance**: Nicht zu viele Extra-Calls
6. **Maintenance**: Aktiv maintained, stabile API

---

## ğŸ” Agent Frameworks Ãœbersicht

### 1. smolagents (Hugging Face) â­ BEREITS VORHANDEN

**Status**: `smolagents_runner.py` existiert bereits!

**Pros**:
- âœ… Bereits in SelfAI integriert
- âœ… UnterstÃ¼tzt custom LLM via Model Interface
- âœ… Leichtgewichtig (keine schweren Dependencies)
- âœ… Simple API (`ToolCallingAgent`)
- âœ… Tool schema aus tool_registry.py kompatibel
- âœ… Von Hugging Face maintained

**Cons**:
- âš ï¸ Relativ neu (weniger mature als LangChain)
- âš ï¸ Kleinere Community

**Code Example**:
```python
from smolagents import ToolCallingAgent, Tool

agent = ToolCallingAgent(
    model=custom_model,  # Works with MiniMax!
    tools=tools_list,
    max_steps=10
)

result = agent.run("Welche Tools hast du?")
# Agent calls list_selfai_files automatically!
```

**Integration Effort**: ğŸŸ¢ Low (30-60 Min) - already has runner!

---

### 2. LangChain Agents

**Package**: `langchain`

**Pros**:
- âœ… Sehr mature, groÃŸe Community
- âœ… Viele Beispiele und Tutorials
- âœ… UnterstÃ¼tzt custom LLMs via BaseChatModel
- âœ… Flexible Agent Types (ReAct, Structured, etc.)
- âœ… Built-in Tool-Calling

**Cons**:
- âŒ Sehr schwer (viele Dependencies)
- âŒ Komplexe API (viele Abstraktionen)
- âŒ Frequent breaking changes zwischen Versionen
- âŒ Overhead: viele interne Calls

**Code Example**:
```python
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.tools import Tool

agent = create_tool_calling_agent(
    llm=custom_llm_wrapper,
    tools=tools,
    prompt=prompt_template
)

executor = AgentExecutor(agent=agent, tools=tools)
result = executor.invoke({"input": "Welche Tools hast du?"})
```

**Integration Effort**: ğŸŸ¡ Medium (2-3 Hours) - complex wrapper needed

---

### 3. LlamaIndex Agents (ReAct Agent)

**Package**: `llama-index`

**Pros**:
- âœ… Gute RAG Integration (falls spÃ¤ter needed)
- âœ… UnterstÃ¼tzt custom LLMs
- âœ… Einfachere API als LangChain
- âœ… ReAct Agent funktioniert gut

**Cons**:
- âš ï¸ Fokus auf RAG/Retrieval (Overhead fÃ¼r reine Tool-Calling)
- âš ï¸ Mittlere Dependencies
- âŒ Tools mÃ¼ssen als FunctionTool gewrappt werden

**Code Example**:
```python
from llama_index.core.agent import ReActAgent
from llama_index.core.tools import FunctionTool

tools = [FunctionTool.from_defaults(fn=tool.run) for tool in tools_list]

agent = ReActAgent.from_tools(
    tools=tools,
    llm=custom_llm,
    verbose=True
)

result = agent.chat("Welche Tools hast du?")
```

**Integration Effort**: ğŸŸ¡ Medium (1-2 Hours) - tool wrapping needed

---

### 4. Autogen (Microsoft)

**Package**: `pyautogen`

**Pros**:
- âœ… Multi-agent conversations
- âœ… Code execution capabilities
- âœ… Von Microsoft maintained

**Cons**:
- âŒ Overkill fÃ¼r single-agent use case
- âŒ Fokus auf multi-agent (nicht was wir brauchen)
- âŒ Komplexere Setup

**Integration Effort**: ğŸ”´ High (3+ Hours) - too complex for our needs

---

### 5. OpenAI Assistants API (Native)

**Package**: `openai`

**Pros**:
- âœ… Native OpenAI Tool-Calling
- âœ… Sehr einfache API

**Cons**:
- âŒ NUR fÃ¼r OpenAI Models (nicht MiniMax!)
- âŒ Cloud-only (keine custom LLMs)
- âŒ Nicht relevant fÃ¼r SelfAI

**Integration Effort**: âŒ Not Applicable (doesn't support MiniMax)

---

### 6. CrewAI

**Package**: `crewai`

**Pros**:
- âœ… Multi-agent orchestration
- âœ… Role-based agents

**Cons**:
- âŒ Fokus auf multi-agent teams (Overkill)
- âŒ Wrapper um LangChain (noch mehr Overhead)
- âŒ Zu komplex fÃ¼r unseren Use Case

**Integration Effort**: ğŸ”´ High - unnecessary complexity

---

### 7. Simple Custom Loop (DIY)

**No Package** - Pure Python

**Pros**:
- âœ… Volle Kontrolle
- âœ… Keine Dependencies
- âœ… Genau auf SelfAI zugeschnitten
- âœ… Leichtgewichtig

**Cons**:
- âŒ MÃ¼ssen alles selbst bauen
- âŒ Tool-Call Parsing selbst implementieren
- âŒ Retry-Logik selbst bauen
- âŒ Mehr Maintenance

**Code Example**:
```python
def run_agent_loop(llm, user_input, tools, max_steps=10):
    for step in range(max_steps):
        response = llm.generate(user_input)

        # Parse tool call from response
        if "<tool_call>" in response:
            tool_name, args = parse_tool_call(response)
            result = execute_tool(tool_name, args)
            user_input = f"Tool result: {result}"
        else:
            return response  # Final answer

    return "Max steps reached"
```

**Integration Effort**: ğŸŸ¡ Medium (2-3 Hours) - but full control

---

## ğŸ“Š Comparison Matrix

| Framework | Effort | MiniMax Support | Lightweight | Mature | Tool UI | Score |
|-----------|--------|-----------------|-------------|--------|---------|-------|
| **smolagents** | ğŸŸ¢ Low | âœ… Yes | âœ… Yes | âš ï¸ Medium | âœ… Easy | **9/10** â­ |
| **LangChain** | ğŸŸ¡ Med | âœ… Yes | âŒ Heavy | âœ… High | âš ï¸ Complex | 6/10 |
| **LlamaIndex** | ğŸŸ¡ Med | âœ… Yes | âš ï¸ Medium | âœ… High | âš ï¸ Medium | 7/10 |
| **Autogen** | ğŸ”´ High | âš ï¸ Maybe | âŒ Heavy | âœ… High | âŒ Complex | 4/10 |
| **DIY Loop** | ğŸŸ¡ Med | âœ… Yes | âœ… Yes | âŒ None | âœ… Full Control | 7/10 |
| **CrewAI** | ğŸ”´ High | âš ï¸ Maybe | âŒ Heavy | âš ï¸ Medium | âŒ Complex | 3/10 |

---

## ğŸ† Recommendation: smolagents + Custom Enhancements

### Why smolagents wins:

1. **Already Integrated**: `smolagents_runner.py` exists!
2. **Works with MiniMax**: Custom Model interface
3. **Lightweight**: No bloat, fast
4. **Easy UI Integration**: Simple to hook into tool calls
5. **Lowest Effort**: 30-60 min implementation

### Enhancement Strategy:

**Keep smolagents BUT enhance it with custom features:**

```python
# Enhanced smolagents runner with SelfAI features

class SelfAIAgent(ToolCallingAgent):
    """Enhanced smolagents agent with UI feedback."""

    def __init__(self, model, tools, ui=None, **kwargs):
        super().__init__(model, tools, **kwargs)
        self.ui = ui

    def execute_tool_call(self, tool_call):
        tool_name = tool_call.name
        args = tool_call.arguments

        # UI Feedback BEFORE execution
        if self.ui:
            self.ui.show_tool_call(tool_name, args)

        # Execute tool (original smolagents logic)
        result = super().execute_tool_call(tool_call)

        return result
```

**Benefits**:
- âœ… Best of both worlds: smolagents stability + custom control
- âœ… UI integration built-in
- âœ… Can add SelfAI-specific features later
- âœ… Minimal code changes

---

## ğŸš€ Implementation Plan (smolagents Enhanced)

### Phase 1: Core Integration (30 Min)

**File**: `selfai/core/selfai_agent.py` (NEW)

```python
"""SelfAI Enhanced Agent with Tool-Calling and UI Feedback."""

from smolagents import ToolCallingAgent
from typing import Any, Optional, List

class SelfAIAgent(ToolCallingAgent):
    """
    Enhanced smolagents ToolCallingAgent with:
    - UI feedback for tool calls
    - SelfAI-specific logging
    - Integration with tool_registry
    """

    def __init__(
        self,
        model,
        tools: List[Any],
        ui=None,
        max_steps: int = 10,
        verbose: bool = True,
        **kwargs
    ):
        super().__init__(
            model=model,
            tools=tools,
            max_steps=max_steps,
            **kwargs
        )
        self.ui = ui
        self.verbose = verbose

    def execute_tool_call(self, tool_call):
        """Override to add UI feedback."""
        tool_name = tool_call.name
        args = tool_call.arguments

        # UI Feedback (Auge-Emoji fÃ¼r Introspection Tools!)
        if self.ui:
            self.ui.show_tool_call(tool_name, args)

        # Optional: Verbose logging
        if self.verbose:
            print(f"[Agent] Executing: {tool_name}")

        # Execute tool via smolagents
        result = super().execute_tool_call(tool_call)

        return result
```

---

### Phase 2: SelfAI Main Loop Integration (30 Min)

**File**: `selfai/selfai.py`

```python
# At top
from selfai.core.selfai_agent import SelfAIAgent
from selfai.core.smolagents_runner import _SelfAIModel
from selfai.tools.tool_registry import get_all_tool_schemas

# In main loop configuration
ENABLE_AGENT_MODE = config.system.get('enable_agent_mode', True)

# Convert tools to smolagents format
def prepare_tools_for_agent():
    """Convert registered tools to smolagents format."""
    from selfai.tools.tool_registry import _TOOL_REGISTRY

    smol_tools = []
    for tool in _TOOL_REGISTRY.values():
        smol_tools.append(tool.to_smol_tool())

    return smol_tools

# In main loop - REPLACE direct LLM call with Agent
if not user_input.startswith('/') and ENABLE_AGENT_MODE:
    # Use SelfAI Agent instead of direct LLM
    if not hasattr(locals(), 'selfai_agent'):
        # Initialize agent once
        model = _SelfAIModel(llm_interface)
        tools = prepare_tools_for_agent()

        selfai_agent = SelfAIAgent(
            model=model,
            tools=tools,
            ui=ui,
            max_steps=10
        )

    # Run agent
    ui.start_spinner("SelfAI denkt nach...")
    try:
        response = selfai_agent.run(user_input)
        ui.stop_spinner()
        print(f"\nSelfAI: {response}")
    except Exception as e:
        ui.stop_spinner(f"Agent Fehler: {e}", "error")

else:
    # Fallback: Direct LLM call (for /commands or if agent disabled)
    # ... existing code ...
```

---

### Phase 3: Config Integration (5 Min)

**File**: `config.yaml`

```yaml
system:
  streaming_enabled: true
  enable_agent_mode: true  # NEW: Toggle agent on/off
  agent_max_steps: 10      # NEW: Max tool-calling iterations
  agent_verbose: true      # NEW: Verbose logging
```

---

## ğŸ§ª Testing Plan

### Test 1: Basic Tool-Calling

```bash
python selfai/selfai.py
```

```
Du: Welche Tools hast du?

Expected:
ğŸ‘ï¸ ğŸ“ Inspiziere Dateien: list_selfai_files â†’ tools/
ğŸ‘ï¸ ğŸ“„ Lese Code: read_selfai_code â†’ tools/tool_registry.py

SelfAI: Ich habe 15 registrierte Tools: ...
```

### Test 2: Multi-Step Reasoning

```
Du: Wie funktioniert dein Execution Dispatcher? Lies den Code!

Expected:
ğŸ‘ï¸ ğŸ” Durchsuche Code: search_selfai_code â†’ 'ExecutionDispatcher'
ğŸ‘ï¸ ğŸ“„ Lese Code: read_selfai_code â†’ core/execution_dispatcher.py

SelfAI: Der ExecutionDispatcher ist in core/execution_dispatcher.py...
```

### Test 3: Aider Integration

```
Du: FÃ¼ge eine Funktion add(a, b) zu math_utils.py hinzu

Expected:
ğŸ¤– Aider Task: run_aider_task

SelfAI: Ich habe Aider aufgerufen...
```

---

## ğŸ“ˆ Benefits

### With Agent Framework:

**Before** (Direct LLM):
```
User: Welche Tools hast du?
MiniMax: Ich habe verschiedene Tools... (HALLUZINATION)
```

**After** (Agent + Tools):
```
User: Welche Tools hast du?
Agent: ğŸ‘ï¸ ğŸ“ list_selfai_files("tools")
        ğŸ‘ï¸ ğŸ“„ read_selfai_code("tools/tool_registry.py")
        â†’ "Ich habe 15 Tools: ..." (FACTUAL!)
```

### Advantages:

1. âœ… **Autonomous Tool Usage**: Agent entscheidet WANN Tools zu nutzen
2. âœ… **No Hallucinations**: Liest echten Code statt zu raten
3. âœ… **Visual Feedback**: User sieht was passiert (Auge-Emoji!)
4. âœ… **Multi-Step Reasoning**: Agent kann mehrere Tools kombinieren
5. âœ… **Introspection Tools WORK**: Self-Awareness funktioniert!

---

## ğŸ¯ Timeline

| Phase | Aufgabe | Zeit | Status |
|-------|---------|------|--------|
| 1 | Create `selfai_agent.py` | 30 Min | ğŸ”œ Next |
| 2 | Integrate into `selfai.py` | 30 Min | ğŸ”œ Next |
| 3 | Add config options | 5 Min | ğŸ”œ Next |
| 4 | Test introspection tools | 15 Min | ğŸ”œ Next |
| 5 | Document & refine | 10 Min | ğŸ”œ Next |
| **Total** | | **90 Min** | |

---

## ğŸ”„ Alternative: Hybrid Approach

**If smolagents has issues**, fallback to:

### DIY Tool-Calling Loop

```python
def run_selfai_agent(llm, user_input, tools, ui, max_steps=10):
    """Custom lightweight agent loop."""

    history = []

    for step in range(max_steps):
        # 1. Get LLM response with tool options
        prompt = build_prompt_with_tools(user_input, tools, history)
        response = llm.generate(prompt)

        # 2. Check if tool call in response
        tool_call = parse_tool_call(response)

        if tool_call:
            tool_name, args = tool_call

            # UI Feedback
            ui.show_tool_call(tool_name, args)

            # Execute
            result = execute_tool(tool_name, args, tools)

            # Add to history
            history.append({
                "tool": tool_name,
                "args": args,
                "result": result
            })

            # Continue with result
            user_input = f"Tool result: {result}. Continue."
        else:
            # Final answer
            return response

    return "Max steps reached"
```

**Effort**: 2-3 Hours
**Use if**: smolagents incompatible with MiniMax API

---

## âœ… Final Recommendation

### Primary: smolagents Enhanced (90 Min) â­

**Why**:
- Already have `smolagents_runner.py`
- Proven to work with custom LLMs
- Lightweight, fast
- UI integration trivial
- Lowest risk

**Implementation**:
1. Create `SelfAIAgent` class (extends ToolCallingAgent)
2. Add UI callbacks
3. Integrate into main loop
4. Test with introspection tools

### Fallback: DIY Loop (if needed)

**Use if**: smolagents doesn't work well with MiniMax

---

**Created**: 2025-01-21
**Next Action**: Implement `SelfAIAgent` with smolagents
**Expected Result**: SelfAI becomes autonomous tool-using agent with visual feedback!
