# ğŸ¤– Gemini as Judge - SelfAI Evaluation System

## Overview

**Gemini-as-Judge** ist ein **READ-ONLY Beobachter** der SelfAI's **komplette** Task-Execution bewertet (Plan + Subtasks + Merge). Es Ã¤ndert **NIE** Code oder Files - es beobachtet nur und gibt Feedback!

**WICHTIG**:
- Gemini Judge evaluiert **NACH** der Merge-Phase, um die finale Output-QualitÃ¤t zu bewerten
- Gemini Judge lÃ¤uft in **One-Shot Mode** ohne Session-Speicherung (keine Pollution der normalen Gemini CLI Nutzung)

## ğŸ¯ Was wird bewertet?

### **4 Hauptmetriken (jeweils 0-10):**

| Metrik | Beschreibung | Gewichtung |
|--------|--------------|------------|
| **Task Completion** | Hat es die Aufgabe erfÃ¼llt? | 40% |
| **Code Quality** | Ist der Code/Output gut? | 20% |
| **Efficiency** | War die AusfÃ¼hrung effizient? | 20% |
| **Goal Adherence** | Passt es genau zum Ziel? | 20% |

### **Overall Score: 0-100**

Gewichteter Durchschnitt der 4 Metriken.

---

## ğŸš¦ Ampel-System (Traffic Light)

| Ampel | Score | Bedeutung |
|-------|-------|-----------|
| ğŸŸ¢ **GREEN** | 80-100 | Sehr gut! Task erfolgreich |
| ğŸŸ¡ **YELLOW** | 50-79 | Okay, aber Verbesserungspotential |
| ğŸ”´ **RED** | 0-49 | Verbesserungsbedarf |

---

## ğŸ“Š Output-Format

Nach jeder `/plan` Execution siehst du:

```
============================================================
ğŸŸ¢ GEMINI JUDGE EVALUATION
============================================================

ğŸ¯ OVERALL SCORE: 85.0/100

ğŸ“Š DETAILED METRICS:
   Task Completion:  9.0/10  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
   Code Quality:     7.5/10  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
   Efficiency:       8.5/10  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ
   Goal Adherence:   8.0/10  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

ğŸ’¬ SUMMARY:
   Task wurde erfolgreich umgesetzt. Code ist sauber und
   gut dokumentiert. Kleinere Optimierungen mÃ¶glich.

âœ… STRENGTHS:
   â€¢ Klare Struktur und gute Lesbarkeit
   â€¢ Umfassende Fehlerbehandlung
   â€¢ Effiziente Tool-Nutzung

âš ï¸  WEAKNESSES:
   â€¢ Einige Redundanzen im Code
   â€¢ Tests fehlen noch

ğŸ’¡ RECOMMENDATIONS:
   â€¢ Unit-Tests hinzufÃ¼gen
   â€¢ Code-Kommentare erweitern
   â€¢ Performance-Profiling durchfÃ¼hren

============================================================
```

---

## ğŸ”§ Technische Details

### **Gemini CLI Integration**

```python
# Gemini wird via CLI im ONE-SHOT Mode aufgerufen (keine Session):
echo "Prompt..." | gemini

# WICHTIG: Kein --resume, keine Session-Speicherung!
# stderr wird unterdrÃ¼ckt (keine Startup-Logs)
# stdout enthÃ¤lt nur JSON Response

# Output wird geparst:
{
  "task_completion": 8.5,
  "code_quality": 7.0,
  ...
}
```

**Session-Isolation**:
- Gemini Judge verwendet **keine Sessions** (keine --resume Flag)
- Jede Evaluation ist ein **frischer One-Shot Call**
- **Keine Pollution** der normalen Gemini CLI Nutzung
- Keine .gemini-session Files werden erstellt

### **Read-Only Guarantee** âœ…

Gemini Judge hat:
- âŒ **KEINE** Schreibrechte auf Files
- âŒ **KEINE** Code-Ã„nderungs-Permissions
- âŒ **KEINE** Tool-Calling Abilities
- âœ… **NUR** Lese-Zugriff auf Output
- âœ… **NUR** Evaluation & Feedback

### **Was Gemini sieht:**

1. **Original Goal** - Was User wollte
2. **Subtask Outputs** - Alle Zwischenergebnisse der Subtasks
3. **Merge Result** - Die finale zusammengefÃ¼gte Antwort (wichtigste Metrik!)
4. **Plan Details** - Welche Subtasks ausgefÃ¼hrt wurden
5. **Execution Time** - Wie lange die gesamte Pipeline dauerte
6. **Files Changed** - Welche Files geÃ¤ndert wurden (via git diff)

### **Was Gemini NICHT sieht:**

- âŒ Kompletter Code-Inhalt (nur Output-Snippets)
- âŒ API Keys oder Secrets
- âŒ Private User-Daten

---

## ğŸ“ Score Speicherung

Alle Bewertungen werden gespeichert in:

```
memory/judge_scores/
â”œâ”€â”€ README.md
â”œâ”€â”€ 20251217-150000_erstelle-dokumentation_score.json
â”œâ”€â”€ 20251217-151200_fix-bug_score.json
â””â”€â”€ 20251217-152000_refactor-code_score.json
```

### **Score-File Format:**

```json
{
  "task_completion": 9.0,
  "code_quality": 7.5,
  "efficiency": 8.5,
  "goal_adherence": 8.0,
  "overall_score": 85.0,
  "traffic_light": "ğŸŸ¢",
  "summary": "Task erfolgreich...",
  "strengths": ["...", "..."],
  "weaknesses": ["..."],
  "recommendations": ["...", "..."]
}
```

---

## ğŸš€ Usage

### **Automatic Evaluation**

Nach jedem `/plan` wird **automatisch** evaluiert:

```bash
Du: /plan Erstelle eine README Datei

SelfAI: [FÃ¼hrt Plan aus...]
        Plan erfolgreich ausgefÃ¼hrt. âœ…

        ğŸ¤– Gemini Judge evaluiert die AusfÃ¼hrung...

        [Shows score with traffic light]
```

### **Manual Check Scores**

```bash
# View latest score
cat memory/judge_scores/*.json | tail -1 | jq .

# View all scores
ls -lt memory/judge_scores/*.json
```

---

## ğŸ“ˆ Use Cases

### **1. Quality Assurance**

```
Nach jedem Task â†’ Siehst du sofort ob QualitÃ¤t stimmt
ğŸŸ¢ Green = Ship it!
ğŸŸ¡ Yellow = Review needed
ğŸ”´ Red = Redo required
```

### **2. Learning & Improvement**

```
Gemini's Recommendations helfen:
- Wo sind Schwachstellen?
- Was kann verbessert werden?
- Wie kann man effizienter sein?
```

### **3. Historical Analysis**

```bash
# Compare scores over time
jq '.overall_score' memory/judge_scores/*.json

# See improvement trend
# 50 â†’ 65 â†’ 75 â†’ 85 = SelfAI lernt! ğŸ“ˆ
```

---

## âš™ï¸ Configuration

### **Judge Settings** (in selfai.py)

```python
# Line 1983: Initialize judge
judge = GeminiJudge(
    gemini_cli_path="gemini"  # Custom path if needed
)

# Line 2010: Evaluate with custom settings
score = judge.evaluate_task(
    original_goal=goal_text,
    execution_output=output,
    plan_data=plan_data,
    execution_time=exec_time,
    files_changed=files
)
```

### **Disable Judge** (if needed)

Kommentiere aus in `selfai.py` (Zeile 1977-2029):

```python
# # GEMINI AS JUDGE: Evaluate execution
# try:
#     from selfai.core.gemini_judge import ...
#     ...
# except Exception:
#     pass
```

---

## ğŸ› Troubleshooting

### **"Gemini CLI nicht verfÃ¼gbar"**

**Problem:** Gemini CLI nicht installiert

**LÃ¶sung:**
```bash
# Install Gemini CLI (Node.js required)
npm install -g @google/generative-ai-cli

# Or via yarn
yarn global add @google/generative-ai-cli

# Verify
gemini --version
```

### **"Gemini Judge Fehler: Timeout"**

**Problem:** Gemini antwortet nicht schnell genug

**LÃ¶sung:** Timeout erhÃ¶hen in `gemini_judge.py` (Zeile 82):

```python
result = subprocess.run(
    ...,
    timeout=60  # Increase from 30 to 60
)
```

### **"Parse error: Invalid JSON"**

**Problem:** Gemini gibt kein gÃ¼ltiges JSON zurÃ¼ck

**LÃ¶sung:** Automatischer Fallback zu neutralem Score (50/100, ğŸŸ¡)

---

## ğŸ’¡ Best Practices

### **1. Review Scores Regularly**

```bash
# Weekly review
ls -lt memory/judge_scores/ | head -10
```

### **2. Learn from Weaknesses**

Gemini's Weaknesses sind Verbesserungs-Opportunities!

### **3. Track Improvement**

```bash
# Plot scores over time
jq '.overall_score' memory/judge_scores/*.json | \
  python -c "
import sys
scores = [float(x) for x in sys.stdin]
print(f'Average: {sum(scores)/len(scores):.1f}')
print(f'Trend: {scores[-5:]}')
"
```

### **4. Use for Decision-Making**

```
ğŸŸ¢ 85+ = Production-ready
ğŸŸ¡ 65-84 = Needs review
ğŸŸ¡ 50-64 = Significant improvements needed
ğŸ”´ <50 = Redo task
```

---

## ğŸ”® Future Enhancements

Planned features:

- [ ] **Historical Trend Graphs** - Visualize score history
- [ ] **Category-Specific Judges** - Different judges for different task types
- [ ] **Multi-Judge Consensus** - Ask multiple LLMs and average
- [ ] **Auto-Improvement Loop** - If Red â†’ Trigger /selfimprove
- [ ] **Leaderboard** - Track best-scoring tasks
- [ ] **Judge Training** - Fine-tune on past evaluations

---

## ğŸ“š Technical Architecture

```
/plan Command
    â†“
Execute Plan (dispatcher.run())
    â†“
Execute Merge Phase (merge.run())
    â†“
Collect Complete Results:
  - User goal (original input)
  - All subtask outputs
  - Merge result (final answer)
  - Execution time (total)
  - Files changed (git diff)
    â†“
Gemini CLI Evaluation (ONE-SHOT MODE):
  - Read complete output (READ-ONLY!)
  - Evaluate quality (Task/Code/Efficiency/Goal)
  - Generate JSON scores
  - NO SESSION SAVED
    â†“
Display Traffic Light + Scores
    â†“
Save to memory/judge_scores/
```

---

## ğŸ“ Example Evaluations

### **Example 1: Excellent Execution**

```
ğŸŸ¢ OVERALL SCORE: 92.0/100

Metrics:
  Task Completion:  9.5/10
  Code Quality:     9.0/10
  Efficiency:       9.0/10
  Goal Adherence:   9.5/10

Strengths:
  â€¢ Perfect implementation
  â€¢ Clean, well-documented code
  â€¢ Efficient execution

Weaknesses:
  â€¢ None significant

Recommendations:
  â€¢ Add integration tests
  â€¢ Consider edge cases
```

### **Example 2: Needs Improvement**

```
ğŸŸ¡ OVERALL SCORE: 68.0/100

Metrics:
  Task Completion:  7.0/10
  Code Quality:     6.0/10
  Efficiency:       7.5/10
  Goal Adherence:   7.0/10

Strengths:
  â€¢ Task completed
  â€¢ Basic functionality works

Weaknesses:
  â€¢ Missing error handling
  â€¢ Code duplication
  â€¢ No documentation

Recommendations:
  â€¢ Add try-catch blocks
  â€¢ Refactor duplicated code
  â€¢ Write docstrings
```

### **Example 3: Critical Issues**

```
ğŸ”´ OVERALL SCORE: 42.0/100

Metrics:
  Task Completion:  5.0/10
  Code Quality:     3.0/10
  Efficiency:       4.5/10
  Goal Adherence:   5.0/10

Strengths:
  â€¢ Attempted implementation

Weaknesses:
  â€¢ Core functionality incomplete
  â€¢ Multiple bugs present
  â€¢ Poor code structure
  â€¢ Doesn't meet requirements

Recommendations:
  â€¢ Redo task with clearer plan
  â€¢ Review requirements carefully
  â€¢ Add comprehensive testing
  â€¢ Consider using /selfimprove
```

---

## ğŸ”’ Security & Privacy

### **What Gemini Can See:**
- âœ… Task goals and objectives
- âœ… Execution output (truncated)
- âœ… Plan structure
- âœ… File names (not content!)
- âœ… Performance metrics

### **What Gemini CANNOT See:**
- âŒ Full source code
- âŒ API keys or secrets
- âŒ Private user data
- âŒ System internals

### **Data Handling:**
- All evaluations stored locally
- No data sent to external servers (except Gemini API for eval)
- Scores can be deleted anytime

---

**Remember:** Gemini Judge ist ein **Helfer**, kein **Richter**!

Nutze das Feedback konstruktiv um besser zu werden! ğŸš€âœ¨

---

**Last Updated:** 2025-12-17
**Version:** 1.0.0
**Status:** âœ… Production Ready
